% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/impgrplasso.R
\name{impgrplasso}
\alias{impgrplasso}
\title{LASSO Regression for Multiply Imputed Datasets using a Grouped Penalty}
\usage{
impgrplasso(
  impdatlist,
  lams,
  outname,
  prednames = NULL,
  forcedin = NULL,
  kfolds = 10,
  kfoldseed = 10,
  scalecenter = TRUE,
  dummify = TRUE
)
}
\arguments{
\item{impdatlist}{A list of data frames generated by multiple imputation.
For example, one could obtain a 'mice' package-derived 'mids' class object
with \code{imp <- mice(nhanes)} and then obtain from that a list of imputed
data frames with \code{dlist <- lapply(1:imp$m, function(x) complete(imp, x))}.}

\item{lams}{Either a single lambda value or a vector of lambda values. If one
value is provided, the function will perform the MI-LASSO on the full dataset
using only that single lambda value. If a vector of values is provided, the
function will perform cross-validation to obtain fold- and imputation-specific
as well as averaged loss values and coefficients for each lambda value so
that an optimal lambda can be chosen.}

\item{outname}{A column name for the dependent variable. This can be continuous
or binary. In the case of the latter, a LASSO logistic regression will be
performed.}

\item{prednames}{Column names for the independent variables. These should be
free of underscores. If dummy variables have already been made for the list
of data frames \code{impdatlist}, provide those names with underscores between
the variable name and the level (e.g., "sex_male").}

\item{forcedin}{This is an optional vector of column names that should be a
subset of \code{prednames} that identifies unpenalized variables to be
"forced in" to the model due to them not experiencing any shrinkage.}

\item{kfolds}{If a vector of lambda values is provided for the argument
\code{lams}, \code{kfolds} provides the number of cross-validation folds for
the cross-validation process. This defaults to 10.}

\item{kfoldseed}{The rows chosen for each k-fold cross-validation are randomly
selected once at the beginning of the function and then this selection is used
consistently throughout subsequent steps. This value sets a seed for that
random process. This defaults to 10.}

\item{scalecenter}{If TRUE (default), the function will scale and center all
variables prior to calculations by subtracting the means of each variable and
dividing by the standard deviations. This is recommended for LASSO regression,
but one can also perform their own form of standardization in the list of data
frames and set this to FALSE if they prefer another standardization approach.}

\item{dummify}{If TRUE (default), the function will produce dummy variables
for all variables in \code{prednames} of classes 'factor' or 'character'. This
can be set to FALSE if one wants to create dummy variables ahead of time and
include them in the list of data frames \code{impdatlist}.}
}
\value{
\code{impgrplasso} returns a list which contains:

\item{Coef}{If \code{lams} is a vector, this is a list of fold-specific data
frames containing coefficients for each variable for specific imputed
datasets and lambda values. If \code{lams} is a single value, this is a
single data frame with variable- and imputation-specific coefficients.}
\item{MeanCoef}{If \code{lams} is a vector of length > 1, this is a data
frame of mean coefficients across imputed datasets for each variable at
each fold and lambda value. If \code{lams} is a single value, this is a data
frame with mean coefficients across imputed datasets for each variable.}
\item{Loss}{This appears only if \code{lams} is a vector of length > 1, and
it is a data frame showing fold- and imputation-specific loss values and
means for each value of lambda.}
\item{MeanLoss}{This appears only if \code{lams} is a vector of length > 1,
and it is a data frame showing the mean prediction loss for each lambda value.}
\item{Model}{This appears only if \code{lams} is a single value, and it is
the \code{grplasso} model object run on the full dataset.}
\item{Index}{This is the \code{index} argument for the \code{grplasso}
function generated by \code{impgrplasso}.}
\item{allX}{This appears only if \code{lams} is a single value, and it is
the large stacked matrix of independent variables across imputed datasets
generated by \code{impgrplasso}.}
}
\description{
\code{impgrplasso} provides functionality for performing least absolute
shrinkage and selection operator (LASSO) regression on multiply imputed data.
This code combines the group LASSO functionality of the 'grplasso' package
(Meier et al. 2008) with the concepts of the multiple imputation LASSO regression
(MI-LASSO) from Chen and Wang 2013. The concept behind MI-LASSO is that one
can "stack" the imputed datasets and then use a group LASSO penalty to
calculate shared penalties across all imputed versions of the same variable.
Grouped penalties are commonly used for categorical variables with more than
two categories so that the dummy variables resulting from that variable all
experience the same penalization, and this grouping of dummy variables
originating from the same categorical variable is automatically done in the
\code{impgrplasso} function.
}
\details{
One criticism from a review on available methods for multiply imputed LASSO
regression from Gunn et al. 2023 is that the Chen and Wang 2013 MI-LASSO
method should have the optimal lambda value chosen based on cross-validation
and MSE rather than the BIC values Chen and Wang used since the latter is
based on degrees of freedom that are difficult to calculate for LASSO
regression. This function adopts the use of cross validation and an MSE or
log-loss loss function for continuous dependent variables and binary dependent
variables (i.e., for LASSO logistic regression), respectively. If the function
is provided a vector of lambda values, this cross validation and loss
calculation process is performed to identify an optimal lambda value. Once
identified, providing the function a single optimal lambda value will perform
the MI-LASSO regression on the full dataset and return the \code{grplasso} model.

To use \code{impgrplasso}, we must first generate a list of imputed data
frames. This can be done for example using the \code{mice} function from the
'mice' package or using the function \code{mice_by_group} from this package.
The list of data frames must have all categorical columns transformed into
dummy variables. This can either be done beforehand or the user can set the
argument 'dummify' to TRUE (the default), in which case the function will do
that transformation. Note that for proper functioning, variable names should
not contain underscores ("_") so that when the dummy variables are generated,
an underscore can be added by \code{impgrplasso} to separate the variable
name (before the added underscore) from its respective levels (after the added
underscore).
}
\examples{
nhanes$hyp <- as.factor(nhanes$hyp - 1)
# above brings "hyp" from a {1, 2} set of unique values to {0, 1}
imp <- mice(nhanes)
dlist <- lapply(1:imp$m, function(x) complete(imp, x))

singlerun_milasso <- impgrplasso(dlist, 5, "hyp", c("age", "bmi", "chl"),
"age")
# This forces "age" into the model by not penalizing that variable.

summary(singlerun_milasso)

}
\references{
Chen, Q., & Wang, S. (2013). Variable selection for multiply‐imputed data
with application to dioxin exposure study. Statistics in medicine, 32(21),
3646-3659.

Gunn, H. J., Hayati Rezvan P., Fernandez M. I., Comulada W. S. (2023). How
to apply variable selection machine learning algorithms with multiply
imputed data: A missing discussion. Psychological methods, 28(2), 452.

Meier, L., Van De Geer, S., & Bühlmann, P. (2008). The group lasso for
logistic regression. Journal of the Royal Statistical Society Series B:
Statistical Methodology, 70(1), 53-71.
}
